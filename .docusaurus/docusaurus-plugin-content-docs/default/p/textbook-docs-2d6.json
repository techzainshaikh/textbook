{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Introduction","items":[{"type":"link","href":"/textbook/docs/intro","label":"Introduction","docId":"intro","unlisted":false},{"type":"link","href":"/textbook/docs/glossary","label":"Glossary","docId":"glossary","unlisted":false},{"type":"link","href":"/textbook/docs/notation","label":"Notation","docId":"notation","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/textbook/docs/module-1-ros2/intro","label":"Module 1 - The Robotic Nervous System (ROS 2)","docId":"module-1-ros2/intro","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-1-nodes-topics-services","label":"Chapter 1 - Nodes, Topics, Services, Actions","docId":"module-1-ros2/chapter-1-nodes-topics-services","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-1-exercises","label":"Chapter 1 - Exercises","docId":"module-1-ros2/chapter-1-exercises","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-2-rclpy-agents","label":"Chapter 2 - rclpy-based Python Agents","docId":"module-1-ros2/chapter-2-rclpy-agents","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-2-exercises","label":"Chapter 2 - Exercises","docId":"module-1-ros2/chapter-2-exercises","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-3-urdf-modeling","label":"Chapter 3 - URDF Humanoid Modeling","docId":"module-1-ros2/chapter-3-urdf-modeling","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-3-exercises","label":"Chapter 3 - Exercises","docId":"module-1-ros2/chapter-3-exercises","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-4-control-architecture","label":"Chapter 4 - ROS 2 Control Architecture","docId":"module-1-ros2/chapter-4-control-architecture","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-4-exercises","label":"Chapter 4 - Exercises","docId":"module-1-ros2/chapter-4-exercises","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/chapter-5-summary-exercises","label":"Chapter 5 - Summary and Exercises","docId":"module-1-ros2/chapter-5-summary-exercises","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/implementation-plan","label":"Module Implementation Plan","docId":"module-1-ros2/implementation-plan","unlisted":false},{"type":"link","href":"/textbook/docs/module-1-ros2/module-summary","label":"Module Summary","docId":"module-1-ros2/module-summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/textbook/docs/module-2-digital-twin/intro","label":"Introduction to Digital Twin","docId":"module-2-digital-twin/intro","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/chapter-1-physics-simulation","label":"Physics Simulation in Gazebo","docId":"module-2-digital-twin/chapter-1-physics-simulation","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/chapter-2-sensor-simulation","label":"Sensor Simulation in Gazebo","docId":"module-2-digital-twin/chapter-2-sensor-simulation","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/chapter-3-environment-modeling","label":"Environment Modeling for Digital Twins","docId":"module-2-digital-twin/chapter-3-environment-modeling","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/chapter-4-unity-visualization","label":"Unity Visualization for Human-Robot Interaction","docId":"module-2-digital-twin/chapter-4-unity-visualization","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/chapter-4-capstone-integration","label":"Capstone Project - Complete Physical AI System Integration","docId":"module-2-digital-twin/chapter-4-capstone-integration","unlisted":false},{"type":"link","href":"/textbook/docs/module-2-digital-twin/module-summary","label":"Module 2 Summary - The Digital Twin","docId":"module-2-digital-twin/module-summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)","items":[{"type":"link","href":"/textbook/docs/module-3-ai-brain/intro","label":"Introduction to AI-Robot Brain","docId":"module-3-ai-brain/intro","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-1-isaac-platform","label":"Isaac Platform and Ecosystem","docId":"module-3-ai-brain/chapter-1-isaac-platform","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-2-synthetic-data","label":"Synthetic Data Generation for AI Training","docId":"module-3-ai-brain/chapter-2-synthetic-data","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-3-perception-pipelines","label":"Perception Pipelines for Robotics AI","docId":"module-3-ai-brain/chapter-3-perception-pipelines","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-4-nav2-planning","label":"Navigation and Path Planning with Isaac ROS","docId":"module-3-ai-brain/chapter-4-nav2-planning","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-5-reinforcement-learning","label":"Reinforcement Learning for Robotics with Isaac Sim","docId":"module-3-ai-brain/chapter-5-reinforcement-learning","unlisted":false},{"type":"link","href":"/textbook/docs/module-3-ai-brain/chapter-6-sim-to-real","label":"Sim-to-Real Transfer for Humanoid Robots","docId":"module-3-ai-brain/chapter-6-sim-to-real","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/textbook/docs/module-4-vla/intro","label":"Introduction to Vision-Language-Action Systems","docId":"module-4-vla/intro","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/chapter-1-vla-overview","label":"Vision-Language-Action Systems Overview","docId":"module-4-vla/chapter-1-vla-overview","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/chapter-2-speech-recognition","label":"Speech Recognition for Robotics with OpenAI Whisper","docId":"module-4-vla/chapter-2-speech-recognition","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/chapter-3-llm-planning","label":"LLM-Based Task Planning for Robotics","docId":"module-4-vla/chapter-3-llm-planning","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/chapter-4-ros2-actions","label":"ROS 2 Actions for VLA Systems","docId":"module-4-vla/chapter-4-ros2-actions","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/chapter-5-multimodal-perception","label":"Multimodal Perception for Vision-Language-Action Systems","docId":"module-4-vla/chapter-5-multimodal-perception","unlisted":false},{"type":"link","href":"/textbook/docs/module-4-vla/module-summary","label":"Module 4 Summary - Vision-Language-Action Systems","docId":"module-4-vla/module-summary","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","href":"/textbook/docs/capstone-project","label":"Capstone Project","docId":"capstone-project","unlisted":false}]},"docs":{"capstone-project":{"id":"capstone-project","title":"Capstone Project - Humanoid Robotics Integration","description":"Comprehensive capstone project integrating all modules of the Physical AI textbook","sidebar":"tutorialSidebar"},"examples/ros2-publisher":{"id":"examples/ros2-publisher","title":"ROS 2 Publisher Example","description":"Complete ROS 2 Publisher Node with WHAT/WHY Comments"},"examples/ros2-service":{"id":"examples/ros2-service","title":"ROS 2 Service Example","description":"Complete ROS 2 Service Node with WHAT/WHY Comments"},"examples/ros2-subscriber":{"id":"examples/ros2-subscriber","title":"ROS 2 Subscriber Example","description":"Complete ROS 2 Subscriber Node with WHAT/WHY Comments"},"examples/urdf-example":{"id":"examples/urdf-example","title":"URDF Example","description":"Complete Humanoid Robot URDF Model with WHAT/WHY Comments"},"glossary":{"id":"glossary","title":"Glossary","description":"Key terms and definitions for Physical AI and Humanoid Robotics","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Introduction","description":"Introduction to Physical AI and Humanoid Robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-1-exercises":{"id":"module-1-ros2/chapter-1-exercises","title":"Chapter 1 - Exercises","description":"Exercises for ROS 2 communication patterns in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-1-nodes-topics-services":{"id":"module-1-ros2/chapter-1-nodes-topics-services","title":"Chapter 1 - Nodes, Topics, Services, Actions","description":"Understanding ROS 2 communication patterns for humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-2-exercises":{"id":"module-1-ros2/chapter-2-exercises","title":"Chapter 2 - Exercises","description":"Exercises for rclpy-based Python agents in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-2-rclpy-agents":{"id":"module-1-ros2/chapter-2-rclpy-agents","title":"Chapter 2 - rclpy-based Python Agents","description":"Developing Python nodes for humanoid robot control using rclpy","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-3-exercises":{"id":"module-1-ros2/chapter-3-exercises","title":"Chapter 3 - Exercises","description":"Exercises for URDF modeling in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-3-urdf-modeling":{"id":"module-1-ros2/chapter-3-urdf-modeling","title":"Chapter 3 - URDF Humanoid Modeling","description":"Creating robot models for simulation and control using URDF","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-4-control-architecture":{"id":"module-1-ros2/chapter-4-control-architecture","title":"Chapter 4 - ROS 2 Control Architecture","description":"Designing control systems for humanoid robots using ROS 2","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-4-exercises":{"id":"module-1-ros2/chapter-4-exercises","title":"Chapter 4 - Exercises","description":"Exercises for ROS 2 control architecture in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/chapter-5-summary-exercises":{"id":"module-1-ros2/chapter-5-summary-exercises","title":"Chapter 5 - Summary and Exercises","description":"Summary and comprehensive exercises for ROS 2 fundamentals in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/implementation-plan":{"id":"module-1-ros2/implementation-plan","title":"Module Implementation Plan","description":"Complete implementation plan for ROS 2 fundamentals in humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/intro":{"id":"module-1-ros2/intro","title":"Module 1 - The Robotic Nervous System (ROS 2)","description":"Introduction to ROS 2 fundamentals for humanoid robotics","sidebar":"tutorialSidebar"},"module-1-ros2/module-summary":{"id":"module-1-ros2/module-summary","title":"Module Summary","description":"Comprehensive summary of ROS 2 fundamentals for humanoid robotics","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-1-physics-simulation":{"id":"module-2-digital-twin/chapter-1-physics-simulation","title":"Physics Simulation in Gazebo","description":"Understanding physics simulation for digital twins using Gazebo","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-2-sensor-simulation":{"id":"module-2-digital-twin/chapter-2-sensor-simulation","title":"Sensor Simulation in Gazebo","description":"Understanding sensor simulation for digital twins using Gazebo","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-3-environment-modeling":{"id":"module-2-digital-twin/chapter-3-environment-modeling","title":"Environment Modeling for Digital Twins","description":"Creating realistic environments for simulation and testing in digital twins","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-4-capstone-integration":{"id":"module-2-digital-twin/chapter-4-capstone-integration","title":"Capstone Project - Complete Physical AI System Integration","description":"Integrating all modules into a complete humanoid robotics system","sidebar":"tutorialSidebar"},"module-2-digital-twin/chapter-4-unity-visualization":{"id":"module-2-digital-twin/chapter-4-unity-visualization","title":"Unity Visualization for Human-Robot Interaction","description":"Creating immersive visualization environments for robotics using Unity","sidebar":"tutorialSidebar"},"module-2-digital-twin/intro":{"id":"module-2-digital-twin/intro","title":"Introduction to Digital Twin","description":"Introduction to Digital Twin concepts with Gazebo and Unity","sidebar":"tutorialSidebar"},"module-2-digital-twin/module-summary":{"id":"module-2-digital-twin/module-summary","title":"Module 2 Summary - The Digital Twin","description":"Comprehensive summary of the Digital Twin (simulation and visualization) module","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-1-isaac-platform":{"id":"module-3-ai-brain/chapter-1-isaac-platform","title":"Isaac Platform and Ecosystem","description":"Understanding NVIDIA Isaac platform for robotics AI","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-2-synthetic-data":{"id":"module-3-ai-brain/chapter-2-synthetic-data","title":"Synthetic Data Generation for AI Training","description":"Creating synthetic datasets using Isaac Sim for AI model training","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-3-perception-pipelines":{"id":"module-3-ai-brain/chapter-3-perception-pipelines","title":"Perception Pipelines for Robotics AI","description":"Building AI-powered perception systems for humanoid robots using Isaac ROS","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-4-nav2-planning":{"id":"module-3-ai-brain/chapter-4-nav2-planning","title":"Navigation and Path Planning with Isaac ROS","description":"Implementing navigation and path planning systems using Isaac ROS and Nav2","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-5-reinforcement-learning":{"id":"module-3-ai-brain/chapter-5-reinforcement-learning","title":"Reinforcement Learning for Robotics with Isaac Sim","description":"Implementing reinforcement learning algorithms for humanoid robot control using Isaac Sim and NVIDIA Omniverse","sidebar":"tutorialSidebar"},"module-3-ai-brain/chapter-6-sim-to-real":{"id":"module-3-ai-brain/chapter-6-sim-to-real","title":"Sim-to-Real Transfer for Humanoid Robots","description":"Bridging the reality gap between simulation and real-world humanoid robot deployment using domain randomization and system identification","sidebar":"tutorialSidebar"},"module-3-ai-brain/intro":{"id":"module-3-ai-brain/intro","title":"Introduction to AI-Robot Brain","description":"Introduction to AI-Robot Brain concepts with NVIDIA Isaac","sidebar":"tutorialSidebar"},"module-4-vla/chapter-1-vla-overview":{"id":"module-4-vla/chapter-1-vla-overview","title":"Vision-Language-Action Systems Overview","description":"Comprehensive overview of multimodal AI systems that integrate vision, language, and action for humanoid robotics","sidebar":"tutorialSidebar"},"module-4-vla/chapter-2-speech-recognition":{"id":"module-4-vla/chapter-2-speech-recognition","title":"Speech Recognition for Robotics with OpenAI Whisper","description":"Implementing speech recognition systems for humanoid robots using OpenAI Whisper and other speech-to-text technologies","sidebar":"tutorialSidebar"},"module-4-vla/chapter-3-llm-planning":{"id":"module-4-vla/chapter-3-llm-planning","title":"LLM-Based Task Planning for Robotics","description":"Implementing Large Language Model-based planning systems for humanoid robots to decompose high-level commands into executable action sequences","sidebar":"tutorialSidebar"},"module-4-vla/chapter-4-ros2-actions":{"id":"module-4-vla/chapter-4-ros2-actions","title":"ROS 2 Actions for VLA Systems","description":"Implementing ROS 2 action servers and clients for complex task execution in Vision-Language-Action systems","sidebar":"tutorialSidebar"},"module-4-vla/chapter-5-multimodal-perception":{"id":"module-4-vla/chapter-5-multimodal-perception","title":"Multimodal Perception for Vision-Language-Action Systems","description":"Implementing multimodal perception systems that integrate vision, language, and sensor data for humanoid robotics applications","sidebar":"tutorialSidebar"},"module-4-vla/intro":{"id":"module-4-vla/intro","title":"Introduction to Vision-Language-Action Systems","description":"Overview of integrated vision, language, and action systems for humanoid robotics applications","sidebar":"tutorialSidebar"},"module-4-vla/module-summary":{"id":"module-4-vla/module-summary","title":"Module 4 Summary - Vision-Language-Action Systems","description":"Summary and integration of Vision-Language-Action systems for humanoid robotics","sidebar":"tutorialSidebar"},"notation":{"id":"notation","title":"Notation","description":"Mathematical and technical notation used in the textbook","sidebar":"tutorialSidebar"}}}}