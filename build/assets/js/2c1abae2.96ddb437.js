"use strict";(globalThis.webpackChunkphysical_ai_book_humanoid=globalThis.webpackChunkphysical_ai_book_humanoid||[]).push([[4378],{6761(n,e,t){t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"module-4-vla/chapter-3-llm-planning","title":"LLM-Based Task Planning for Robotics","description":"Implementing Large Language Model-based planning systems for humanoid robots to decompose high-level commands into executable action sequences","source":"@site/docs/module-4-vla/chapter-3-llm-planning.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/chapter-3-llm-planning","permalink":"/textbook/docs/module-4-vla/chapter-3-llm-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/Panaversity/physical_ai_book_humanoid/tree/main/docs/module-4-vla/chapter-3-llm-planning.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"LLM-Based Task Planning for Robotics","sidebar_position":4,"description":"Implementing Large Language Model-based planning systems for humanoid robots to decompose high-level commands into executable action sequences","keywords":["LLM planning","task decomposition","robotics","humanoid AI","natural language processing","action sequences"]},"sidebar":"tutorialSidebar","previous":{"title":"Speech Recognition for Robotics with OpenAI Whisper","permalink":"/textbook/docs/module-4-vla/chapter-2-speech-recognition"},"next":{"title":"ROS 2 Actions for VLA Systems","permalink":"/textbook/docs/module-4-vla/chapter-4-ros2-actions"}}');var i=t(4848),s=t(8453);const o={title:"LLM-Based Task Planning for Robotics",sidebar_position:4,description:"Implementing Large Language Model-based planning systems for humanoid robots to decompose high-level commands into executable action sequences",keywords:["LLM planning","task decomposition","robotics","humanoid AI","natural language processing","action sequences"]},r="Chapter 3: LLM-Based Task Planning for Robotics",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"LLM Planning Architecture",id:"llm-planning-architecture",level:3},{value:"Planning Patterns",id:"planning-patterns",level:3},{value:"Implementation",id:"implementation",level:2},{value:"LLM Planning Interface",id:"llm-planning-interface",level:3},{value:"Advanced Planning with Context and Memory",id:"advanced-planning-with-context-and-memory",level:3},{value:"Examples",id:"examples",level:2},{value:"Example 1: Complex Task Planning System",id:"example-1-complex-task-planning-system",level:3},{value:"Example 2: Planning with Safety and Recovery",id:"example-2-planning-with-safety-and-recovery",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Conceptual",id:"conceptual",level:3},{value:"Logical",id:"logical",level:3},{value:"Implementation",id:"implementation-1",level:3}];function p(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"chapter-3-llm-based-task-planning-for-robotics",children:"Chapter 3: LLM-Based Task Planning for Robotics"})}),"\n",(0,i.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Implement LLM-based planning systems that translate high-level commands into executable robot actions"}),"\n",(0,i.jsx)(e.li,{children:"Design task decomposition algorithms using Large Language Models for robotics applications"}),"\n",(0,i.jsx)(e.li,{children:"Integrate LLM planning with robot execution frameworks and action servers"}),"\n",(0,i.jsx)(e.li,{children:"Validate and verify LLM-generated plans for safety and correctness in robotic systems"}),"\n",(0,i.jsx)(e.li,{children:"Handle planning failures and implement fallback strategies for robust robot operation"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(e.p,{children:"Students should have:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsx)(e.li,{children:"Understanding of robotics concepts and action execution (covered in Module 1)"}),"\n",(0,i.jsx)(e.li,{children:"Knowledge of Large Language Models and their capabilities"}),"\n",(0,i.jsx)(e.li,{children:"Familiarity with task planning and decomposition concepts"}),"\n",(0,i.jsx)(e.li,{children:"Basic understanding of natural language processing"}),"\n",(0,i.jsx)(e.li,{children:"Experience with Python programming and API integration"}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,i.jsx)(e.p,{children:"Large Language Model (LLM)-based planning leverages the reasoning and decomposition capabilities of modern AI models to bridge high-level human commands with low-level robot actions. This approach enables more natural interaction with robots while maintaining the precision required for robotic execution."}),"\n",(0,i.jsx)(e.h3,{id:"llm-planning-architecture",children:"LLM Planning Architecture"}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Command Interpretation:"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Natural Language Understanding"}),": Parse high-level commands and identify intent"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Context Extraction"}),": Extract relevant entities, objects, locations, and constraints"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Goal Specification"}),": Convert natural language into structured goal representations"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Task Decomposition:"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Hierarchical Planning"}),": Break down complex tasks into subtasks"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Action Sequencing"}),": Order actions to achieve the desired goal"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Constraint Handling"}),": Consider physical, temporal, and safety constraints"]}),"\n"]}),"\n",(0,i.jsx)(e.p,{children:(0,i.jsx)(e.strong,{children:"Execution Integration:"})}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Action Mapping"}),": Translate LLM-generated steps to robot-specific actions"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Feedback Integration"}),": Incorporate sensor feedback into the planning process"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Plan Adaptation"}),": Adjust plans based on execution outcomes and environmental changes"]}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"planning-patterns",children:"Planning Patterns"}),"\n",(0,i.jsxs)(e.p,{children:[(0,i.jsx)(e.strong,{children:"Sequential Planning"}),": Linear execution of actions from start to goal\n",(0,i.jsx)(e.strong,{children:"Conditional Planning"}),": Decision points based on environmental conditions\n",(0,i.jsx)(e.strong,{children:"Reactive Planning"}),": Real-time adjustments based on sensor feedback\n",(0,i.jsx)(e.strong,{children:"Hierarchical Planning"}),": Multi-level decomposition from high-level goals to primitive actions"]}),"\n",(0,i.jsx)(e.h2,{id:"implementation",children:"Implementation"}),"\n",(0,i.jsx)(e.p,{children:"Let's implement LLM-based task planning for humanoid robotics:"}),"\n",(0,i.jsx)(e.h3,{id:"llm-planning-interface",children:"LLM Planning Interface"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# llm_planning_interface.py\n\nimport openai\nimport json\nimport asyncio\nimport time\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom dataclasses import dataclass\nimport logging\n\n@dataclass\nclass PlanStep:\n    """Represents a single step in a robot plan"""\n    action: str\n    parameters: Dict[str, Any]\n    description: str\n    dependencies: List[str]  # Other steps this step depends on\n    estimated_duration: float  # In seconds\n\n@dataclass\nclass PlanningResult:\n    """Result from the LLM planning process"""\n    success: bool\n    plan: List[PlanStep]\n    reasoning: str\n    confidence: float\n    execution_context: Dict[str, Any]\n    error: Optional[str] = None\n\nclass LLMPlanner:\n    """\n    Large Language Model-based planner for robotics\n    """\n\n    def __init__(self, api_key: str = None, model: str = "gpt-4-turbo"):\n        self.model = model\n        if api_key:\n            openai.api_key = api_key\n        self.logger = logging.getLogger(__name__)\n\n    def create_planning_prompt(self, command: str, robot_capabilities: List[str],\n                              environment_state: Dict[str, Any]) -> str:\n        """Create a prompt for the LLM to generate a plan"""\n        capabilities_str = ", ".join(robot_capabilities)\n        env_state_str = json.dumps(environment_state, indent=2)\n\n        prompt = f"""\nYou are an expert robot task planner. Your job is to decompose high-level commands into detailed, executable steps for a humanoid robot.\n\nRobot Capabilities: {capabilities_str}\n\nCurrent Environment State:\n{env_state_str}\n\nCommand: {command}\n\nPlease generate a detailed plan with the following requirements:\n1. Break down the command into specific, executable actions\n2. Consider the robot\'s capabilities and environmental constraints\n3. Include necessary preconditions and postconditions for each step\n4. Order the steps logically for successful execution\n5. Include error handling and fallback strategies where appropriate\n\nReturn your response in JSON format with the following structure:\n{{\n  "reasoning": "Your step-by-step reasoning for the plan",\n  "plan": [\n    {{\n      "action": "action_name",\n      "parameters": {{"param1": "value1", "param2": "value2"}},\n      "description": "Brief description of what this step does",\n      "dependencies": ["action_name_1", "action_name_2"],  // Actions that must complete before this one\n      "estimated_duration": 2.5  // Estimated time in seconds\n    }}\n  ],\n  "confidence": 0.9  // Confidence level in the plan (0.0 to 1.0)\n}}\n\nEnsure all actions are from the robot\'s capabilities list and all parameters are valid for those actions.\n"""\n        return prompt\n\n    async def generate_plan(self, command: str, robot_capabilities: List[str],\n                           environment_state: Dict[str, Any]) -> PlanningResult:\n        """Generate a plan using the LLM"""\n        try:\n            prompt = self.create_planning_prompt(command, robot_capabilities, environment_state)\n\n            response = await openai.ChatCompletion.acreate(\n                model=self.model,\n                messages=[\n                    {"role": "system", "content": "You are an expert robot task planner. Generate detailed, executable plans."},\n                    {"role": "user", "content": prompt}\n                ],\n                temperature=0.1,  # Low temperature for more deterministic output\n                max_tokens=2000\n            )\n\n            response_text = response.choices[0].message.content.strip()\n\n            # Extract JSON from response\n            json_start = response_text.find(\'{\')\n            json_end = response_text.rfind(\'}\') + 1\n            if json_start != -1 and json_end != 0:\n                json_str = response_text[json_start:json_end]\n                plan_data = json.loads(json_str)\n\n                # Convert to PlanStep objects\n                plan_steps = []\n                for step_data in plan_data.get("plan", []):\n                    step = PlanStep(\n                        action=step_data["action"],\n                        parameters=step_data.get("parameters", {}),\n                        description=step_data.get("description", ""),\n                        dependencies=step_data.get("dependencies", []),\n                        estimated_duration=step_data.get("estimated_duration", 1.0)\n                    )\n                    plan_steps.append(step)\n\n                return PlanningResult(\n                    success=True,\n                    plan=plan_steps,\n                    reasoning=plan_data.get("reasoning", ""),\n                    confidence=plan_data.get("confidence", 0.5),\n                    execution_context={\n                        "original_command": command,\n                        "robot_capabilities": robot_capabilities,\n                        "environment_state": environment_state\n                    }\n                )\n            else:\n                return PlanningResult(\n                    success=False,\n                    plan=[],\n                    reasoning="",\n                    confidence=0.0,\n                    execution_context={},\n                    error=f"Could not extract JSON from LLM response: {response_text}"\n                )\n\n        except json.JSONDecodeError as e:\n            return PlanningResult(\n                success=False,\n                plan=[],\n                reasoning="",\n                confidence=0.0,\n                execution_context={},\n                error=f"JSON decode error: {str(e)}"\n            )\n        except Exception as e:\n            return PlanningResult(\n                success=False,\n                plan=[],\n                reasoning="",\n                confidence=0.0,\n                execution_context={},\n                error=f"Planning error: {str(e)}"\n            )\n\n    def validate_plan(self, plan: List[PlanStep], robot_capabilities: List[str]) -> Tuple[bool, List[str]]:\n        """Validate that the plan is executable with available capabilities"""\n        errors = []\n\n        for step in plan:\n            if step.action not in robot_capabilities:\n                errors.append(f"Action \'{step.action}\' not available in robot capabilities")\n\n            # Check parameter validity (simplified)\n            if not isinstance(step.parameters, dict):\n                errors.append(f"Parameters for action \'{step.action}\' must be a dictionary")\n\n        return len(errors) == 0, errors\n\nclass RobotActionMapper:\n    """\n    Map LLM-generated actions to actual robot commands\n    """\n\n    def __init__(self):\n        # Define mapping from high-level actions to robot-specific commands\n        self.action_mapping = {\n            "navigate_to": "move_base",\n            "pick_object": "grasp",\n            "place_object": "place",\n            "grasp": "gripper_control",\n            "release": "gripper_control",\n            "inspect": "sensor_control",\n            "approach": "move_base",\n            "avoid": "move_base",\n            "wait": "wait",\n            "turn": "rotate"\n        }\n\n        # Define parameter mappings\n        self.parameter_mappings = {\n            "location": "target_pose",\n            "object": "target_object",\n            "position": "target_position",\n            "orientation": "target_orientation",\n            "gripper_position": "gripper_position"\n        }\n\n    def map_action(self, llm_action: str, parameters: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:\n        """Map LLM action to robot action with appropriate parameters"""\n        robot_action = self.action_mapping.get(llm_action, llm_action)\n        robot_params = {}\n\n        for param_name, param_value in parameters.items():\n            robot_param_name = self.parameter_mappings.get(param_name, param_name)\n            robot_params[robot_param_name] = param_value\n\n        # Add default parameters if needed\n        if robot_action == "gripper_control":\n            if "gripper_position" not in robot_params:\n                robot_params["gripper_position"] = 0.8 if llm_action == "grasp" else 0.0\n\n        return robot_action, robot_params\n\nclass ExecutionValidator:\n    """\n    Validate and verify robot execution plans\n    """\n\n    def __init__(self):\n        self.safety_constraints = [\n            self._check_collision_avoidance,\n            self._check_joint_limits,\n            self._check_payload_limits,\n            self._check_workspace_bounds\n        ]\n\n    def validate_for_execution(self, plan: List[PlanStep],\n                              current_state: Dict[str, Any]) -> Tuple[bool, List[str]]:\n        """Validate plan for safe execution"""\n        errors = []\n\n        for step in plan:\n            for constraint_check in self.safety_constraints:\n                is_safe, error_msg = constraint_check(step, current_state)\n                if not is_safe:\n                    errors.append(f"Step \'{step.action}\': {error_msg}")\n\n        return len(errors) == 0, errors\n\n    def _check_collision_avoidance(self, step: PlanStep, current_state: Dict[str, Any]) -> Tuple[bool, str]:\n        """Check if the action could cause collisions"""\n        # This would interface with the robot\'s collision detection system\n        # For demonstration, assume all actions are safe\n        return True, ""\n\n    def _check_joint_limits(self, step: PlanStep, current_state: Dict[str, Any]) -> Tuple[bool, str]:\n        """Check if the action respects joint limits"""\n        # This would check robot joint limits\n        return True, ""\n\n    def _check_payload_limits(self, step: PlanStep, current_state: Dict[str, Any]) -> Tuple[bool, str]:\n        """Check if the action respects payload limits"""\n        # This would check if the robot can handle the payload\n        return True, ""\n\n    def _check_workspace_bounds(self, step: PlanStep, current_state: Dict[str, Any]) -> Tuple[bool, str]:\n        """Check if the action is within workspace bounds"""\n        # This would check if the target position is within workspace\n        return True, ""\n\nclass AdaptivePlanner:\n    """\n    Adaptive planning that can adjust based on execution feedback\n    """\n\n    def __init__(self):\n        self.action_mapper = RobotActionMapper()\n        self.validator = ExecutionValidator()\n\n    def adapt_plan(self, original_plan: List[PlanStep],\n                   execution_feedback: Dict[str, Any]) -> List[PlanStep]:\n        """Adapt the plan based on execution feedback"""\n        # This would modify the plan based on what happened during execution\n        # For example, if an object wasn\'t found, it might add a search step\n        adapted_plan = []\n\n        for step in original_plan:\n            # Check if this step needs adaptation based on feedback\n            if self._needs_adaptation(step, execution_feedback):\n                adapted_steps = self._generate_adaptation(step, execution_feedback)\n                adapted_plan.extend(adapted_steps)\n            else:\n                adapted_plan.append(step)\n\n        return adapted_plan\n\n    def _needs_adaptation(self, step: PlanStep, feedback: Dict[str, Any]) -> bool:\n        """Determine if a step needs adaptation based on feedback"""\n        # Check if the previous execution of similar steps failed\n        failed_actions = feedback.get("failed_actions", [])\n        return step.action in failed_actions\n\n    def _generate_adaptation(self, step: PlanStep, feedback: Dict[str, Any]) -> List[PlanStep]:\n        """Generate adapted steps for a failed action"""\n        # This would generate alternative approaches\n        # For example, if picking failed, try a different grasp strategy\n        if step.action == "pick_object":\n            # Add a search step before picking\n            search_step = PlanStep(\n                action="search_object",\n                parameters=step.parameters,\n                description="Search for the object before attempting to pick it",\n                dependencies=step.dependencies,\n                estimated_duration=2.0\n            )\n            return [search_step, step]\n\n        return [step]\n\ndef create_llm_planner(api_key: str = None) -> LLMPlanner:\n    """Factory function to create an LLM planner"""\n    return LLMPlanner(api_key)\n'})}),"\n",(0,i.jsx)(e.h3,{id:"advanced-planning-with-context-and-memory",children:"Advanced Planning with Context and Memory"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# advanced_planning.py\n\nimport openai\nimport json\nimport asyncio\nimport time\nfrom typing import Dict, Any, List, Optional, Tuple\nfrom dataclasses import dataclass\nimport logging\nfrom datetime import datetime\n\n@dataclass\nclass PlanExecutionRecord:\n    """Record of a plan execution"""\n    plan_id: str\n    command: str\n    plan: List[Dict[str, Any]]\n    execution_time: float\n    success: bool\n    feedback: Dict[str, Any]\n    timestamp: datetime\n\nclass PlanningMemory:\n    """\n    Memory system for learning from past planning experiences\n    """\n\n    def __init__(self):\n        self.execution_history = []\n        self.success_patterns = {}\n        self.failure_patterns = {}\n        self.max_history = 100\n\n    def record_execution(self, record: PlanExecutionRecord):\n        """Record a plan execution for future learning"""\n        self.execution_history.append(record)\n\n        # Keep only recent history\n        if len(self.execution_history) > self.max_history:\n            self.execution_history = self.execution_history[-self.max_history:]\n\n        # Update patterns based on success/failure\n        if record.success:\n            self._update_success_patterns(record)\n        else:\n            self._update_failure_patterns(record)\n\n    def _update_success_patterns(self, record: PlanExecutionRecord):\n        """Update patterns for successful executions"""\n        command_key = self._normalize_command(record.command)\n        if command_key not in self.success_patterns:\n            self.success_patterns[command_key] = []\n\n        self.success_patterns[command_key].append({\n            "plan_structure": [step["action"] for step in record.plan],\n            "environment": record.feedback.get("environment", {}),\n            "execution_time": record.execution_time\n        })\n\n    def _update_failure_patterns(self, record: PlanExecutionRecord):\n        """Update patterns for failed executions"""\n        command_key = self._normalize_command(record.command)\n        if command_key not in self.failure_patterns:\n            self.failure_patterns[command_key] = []\n\n        self.failure_patterns[command_key].append({\n            "plan_structure": [step["action"] for step in record.plan],\n            "failure_reason": record.feedback.get("error", "unknown"),\n            "environment": record.feedback.get("environment", {})\n        })\n\n    def _normalize_command(self, command: str) -> str:\n        """Normalize command for pattern matching"""\n        return command.lower().strip()\n\n    def get_successful_variants(self, command: str) -> List[Dict[str, Any]]:\n        """Get successful plan variants for similar commands"""\n        command_key = self._normalize_command(command)\n        # This would use similarity matching in a real implementation\n        return self.success_patterns.get(command_key, [])\n\n    def get_failure_warnings(self, command: str) -> List[str]:\n        """Get warnings based on past failures"""\n        command_key = self._normalize_command(command)\n        failures = self.failure_patterns.get(command_key, [])\n        return [f["failure_reason"] for f in failures]\n\nclass ContextAwarePlanner:\n    """\n    Planner that uses context and memory to improve planning\n    """\n\n    def __init__(self, api_key: str = None):\n        self.llm_planner = LLMPlanner(api_key)\n        self.memory = PlanningMemory()\n        self.action_mapper = RobotActionMapper()\n        self.validator = ExecutionValidator()\n\n    def create_contextual_prompt(self, command: str, robot_capabilities: List[str],\n                                environment_state: Dict[str, Any]) -> str:\n        """Create a prompt that includes contextual information"""\n        # Get relevant past experiences\n        successful_variants = self.memory.get_successful_variants(command)\n        failure_warnings = self.memory.get_failure_warnings(command)\n\n        capabilities_str = ", ".join(robot_capabilities)\n        env_state_str = json.dumps(environment_state, indent=2)\n\n        # Format successful variants\n        variants_str = ""\n        if successful_variants:\n            variants_str = "Successful variants from similar commands:\\n"\n            for i, variant in enumerate(successful_variants[:2]):  # Limit to 2 examples\n                variants_str += f"Variant {i+1}: {variant[\'plan_structure\']}\\n"\n\n        # Format failure warnings\n        warnings_str = ""\n        if failure_warnings:\n            warnings_str = "Potential failure points to avoid:\\n"\n            for warning in failure_warnings[:3]:  # Limit to 3 warnings\n                warnings_str += f"- {warning}\\n"\n\n        prompt = f"""\nYou are an expert robot task planner. Your job is to decompose high-level commands into detailed, executable steps for a humanoid robot.\n\nRobot Capabilities: {capabilities_str}\n\nCurrent Environment State:\n{env_state_str}\n\n{variants_str}\n{warnings_str}\n\nCommand: {command}\n\nPlease generate a detailed plan with the following requirements:\n1. Break down the command into specific, executable actions\n2. Consider the robot\'s capabilities and environmental constraints\n3. Include necessary preconditions and postconditions for each step\n4. Order the steps logically for successful execution\n5. Include error handling and fallback strategies where appropriate\n6. Consider lessons from past successful executions and failures\n\nReturn your response in JSON format with the following structure:\n{{\n  "reasoning": "Your step-by-step reasoning for the plan, considering past experiences",\n  "plan": [\n    {{\n      "action": "action_name",\n      "parameters": {{"param1": "value1", "param2": "value2"}},\n      "description": "Brief description of what this step does",\n      "dependencies": ["action_name_1", "action_name_2"],  // Actions that must complete before this one\n      "estimated_duration": 2.5  // Estimated time in seconds\n    }}\n  ],\n  "confidence": 0.9  // Confidence level in the plan (0.0 to 1.0)\n}}\n\nEnsure all actions are from the robot\'s capabilities list and all parameters are valid for those actions.\n"""\n        return prompt\n\n    async def generate_contextual_plan(self, command: str, robot_capabilities: List[str],\n                                     environment_state: Dict[str, Any]) -> PlanningResult:\n        """Generate a plan using contextual information from memory"""\n        try:\n            prompt = self.create_contextual_prompt(command, robot_capabilities, environment_state)\n\n            response = await openai.ChatCompletion.acreate(\n                model=self.llm_planner.model,\n                messages=[\n                    {"role": "system", "content": "You are an expert robot task planner. Generate detailed, executable plans considering past experiences."},\n                    {"role": "user", "content": prompt}\n                ],\n                temperature=0.1,\n                max_tokens=2000\n            )\n\n            response_text = response.choices[0].message.content.strip()\n\n            # Extract JSON from response\n            json_start = response_text.find(\'{\')\n            json_end = response_text.rfind(\'}\') + 1\n            if json_start != -1 and json_end != 0:\n                json_str = response_text[json_start:json_end]\n                plan_data = json.loads(json_str)\n\n                # Convert to PlanStep objects\n                plan_steps = []\n                for step_data in plan_data.get("plan", []):\n                    step = PlanStep(\n                        action=step_data["action"],\n                        parameters=step_data.get("parameters", {}),\n                        description=step_data.get("description", ""),\n                        dependencies=step_data.get("dependencies", []),\n                        estimated_duration=step_data.get("estimated_duration", 1.0)\n                    )\n                    plan_steps.append(step)\n\n                return PlanningResult(\n                    success=True,\n                    plan=plan_steps,\n                    reasoning=plan_data.get("reasoning", ""),\n                    confidence=plan_data.get("confidence", 0.5),\n                    execution_context={\n                        "original_command": command,\n                        "robot_capabilities": robot_capabilities,\n                        "environment_state": environment_state\n                    }\n                )\n            else:\n                return PlanningResult(\n                    success=False,\n                    plan=[],\n                    reasoning="",\n                    confidence=0.0,\n                    execution_context={},\n                    error=f"Could not extract JSON from LLM response: {response_text}"\n                )\n\n        except json.JSONDecodeError as e:\n            return PlanningResult(\n                success=False,\n                plan=[],\n                reasoning="",\n                confidence=0.0,\n                execution_context={},\n                error=f"JSON decode error: {str(e)}"\n            )\n        except Exception as e:\n            return PlanningResult(\n                success=False,\n                plan=[],\n                reasoning="",\n                confidence=0.0,\n                execution_context={},\n                error=f"Planning error: {str(e)}"\n            )\n\n    async def execute_plan_with_learning(self, command: str, robot_capabilities: List[str],\n                                       environment_state: Dict[str, Any]) -> PlanExecutionRecord:\n        """Execute a plan and record the experience for learning"""\n        start_time = time.time()\n\n        # Generate plan\n        result = await self.generate_contextual_plan(command, robot_capabilities, environment_state)\n\n        if not result.success:\n            execution_time = time.time() - start_time\n            record = PlanExecutionRecord(\n                plan_id=f"plan_{int(time.time())}",\n                command=command,\n                plan=[],\n                execution_time=execution_time,\n                success=False,\n                feedback={"error": result.error},\n                timestamp=datetime.now()\n            )\n            self.memory.record_execution(record)\n            return record\n\n        # Validate plan\n        is_valid, validation_errors = self.validator.validate_for_execution(\n            result.plan, environment_state\n        )\n\n        if not is_valid:\n            execution_time = time.time() - start_time\n            record = PlanExecutionRecord(\n                plan_id=f"plan_{int(time.time())}",\n                command=command,\n                plan=[step.__dict__ for step in result.plan],\n                execution_time=execution_time,\n                success=False,\n                feedback={"validation_errors": validation_errors},\n                timestamp=datetime.now()\n            )\n            self.memory.record_execution(record)\n            return record\n\n        # In a real system, this would execute the plan on the robot\n        # For simulation, we\'ll assume successful execution\n        execution_time = time.time() - start_time\n        record = PlanExecutionRecord(\n            plan_id=f"plan_{int(time.time())}",\n            command=command,\n            plan=[step.__dict__ for step in result.plan],\n            execution_time=execution_time,\n            success=True,\n            feedback={"environment": environment_state},\n            timestamp=datetime.now()\n        )\n        self.memory.record_execution(record)\n\n        return record\n\ndef create_contextual_planner(api_key: str = None) -> ContextAwarePlanner:\n    """Factory function to create a contextual planner"""\n    return ContextAwarePlanner(api_key)\n'})}),"\n",(0,i.jsx)(e.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(e.h3,{id:"example-1-complex-task-planning-system",children:"Example 1: Complex Task Planning System"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# complex_task_planning.py\n\nimport asyncio\nfrom typing import Dict, Any, List\nimport time\n\nclass ComplexTaskPlanningSystem:\n    """\n    System for planning complex tasks with multiple constraints and dependencies\n    """\n\n    def __init__(self, api_key: str = None):\n        self.contextual_planner = create_contextual_planner(api_key)\n        self.robot_capabilities = [\n            "navigate_to", "pick_object", "place_object", "grasp", "release",\n            "inspect", "approach", "wait", "turn", "detect_object"\n        ]\n\n    async def plan_complex_task(self, command: str, environment_state: Dict[str, Any]) -> Dict[str, Any]:\n        """Plan a complex task with multiple constraints"""\n        print(f"Planning complex task: {command}")\n\n        # Generate initial plan\n        result = await self.contextual_planner.generate_contextual_plan(\n            command, self.robot_capabilities, environment_state\n        )\n\n        if not result.success:\n            return {\n                "success": False,\n                "error": result.error,\n                "reasoning": result.reasoning\n            }\n\n        # Validate the plan\n        is_valid, errors = self.contextual_planner.validator.validate_for_execution(\n            result.plan, environment_state\n        )\n\n        if not is_valid:\n            return {\n                "success": False,\n                "error": f"Plan validation failed: {errors}",\n                "reasoning": result.reasoning\n            }\n\n        # Map high-level actions to robot-specific commands\n        mapped_plan = []\n        for step in result.plan:\n            robot_action, robot_params = self.contextual_planner.action_mapper.map_action(\n                step.action, step.parameters\n            )\n            mapped_plan.append({\n                "robot_action": robot_action,\n                "parameters": robot_params,\n                "description": step.description,\n                "estimated_duration": step.estimated_duration\n            })\n\n        return {\n            "success": True,\n            "plan": mapped_plan,\n            "reasoning": result.reasoning,\n            "confidence": result.confidence,\n            "estimated_total_time": sum(step.estimated_duration for step in result.plan)\n        }\n\n    async def execute_with_monitoring(self, command: str, environment_state: Dict[str, Any]) -> Dict[str, Any]:\n        """Execute a plan with real-time monitoring and adaptation"""\n        # Generate and execute plan\n        execution_record = await self.contextual_planner.execute_plan_with_learning(\n            command, self.robot_capabilities, environment_state\n        )\n\n        # Simulate execution monitoring\n        monitoring_results = {\n            "start_time": time.time(),\n            "estimated_duration": execution_record.execution_time,\n            "steps_completed": len(execution_record.plan) if execution_record.success else 0,\n            "success": execution_record.success\n        }\n\n        return {\n            "execution_record": execution_record,\n            "monitoring": monitoring_results\n        }\n\n    async def handle_multi_object_task(self, objects_to_process: List[Dict[str, Any]],\n                                     base_command_template: str) -> List[Dict[str, Any]]:\n        """Handle tasks that involve multiple objects"""\n        results = []\n\n        for obj in objects_to_process:\n            command = base_command_template.format(object_name=obj["name"], location=obj["location"])\n            environment_state = {\n                "available_objects": [obj],\n                "robot_position": obj.get("robot_start_position", [0, 0, 0]),\n                "workspace_limits": obj.get("workspace_limits", {})\n            }\n\n            result = await self.plan_complex_task(command, environment_state)\n            results.append({\n                "object": obj,\n                "command": command,\n                "plan_result": result\n            })\n\n        return results\n\n# Example usage\nasync def main():\n    """Main function to demonstrate complex task planning"""\n    print("Initializing Complex Task Planning System...")\n\n    # In a real implementation, you would provide an API key\n    # For this example, we\'ll just demonstrate the structure\n    try:\n        planner_system = ComplexTaskPlanningSystem()\n\n        # Example 1: Simple navigation task\n        environment_state = {\n            "objects": [{"name": "red_cube", "location": [1.0, 0.5, 0.0]}],\n            "robot_position": [0, 0, 0],\n            "workspace_limits": {"x": [-2, 2], "y": [-2, 2], "z": [0, 1]}\n        }\n\n        result = await planner_system.plan_complex_task(\n            "Navigate to the red cube and pick it up",\n            environment_state\n        )\n\n        print(f"Planning result: {result[\'success\']}")\n        if result[\'success\']:\n            print(f"Plan confidence: {result[\'confidence\']:.2f}")\n            print(f"Estimated time: {result[\'estimated_total_time\']:.2f}s")\n\n        print("Complex task planning system demonstrated successfully!")\n        print("In a real implementation, this would connect to an LLM API and robot execution system.")\n\n    except Exception as e:\n        print(f"Note: This example requires an LLM API key for full functionality. Error: {e}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})}),"\n",(0,i.jsx)(e.h3,{id:"example-2-planning-with-safety-and-recovery",children:"Example 2: Planning with Safety and Recovery"}),"\n",(0,i.jsx)(e.pre,{children:(0,i.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# planning_with_safety.py\n\nimport asyncio\nimport time\nfrom typing import Dict, Any, List\nimport logging\n\nclass SafePlanningSystem:\n    """\n    Planning system with built-in safety checks and recovery mechanisms\n    """\n\n    def __init__(self, api_key: str = None):\n        self.contextual_planner = create_contextual_planner(api_key)\n        self.robot_capabilities = [\n            "navigate_to", "pick_object", "place_object", "grasp", "release",\n            "inspect", "approach", "wait", "turn", "detect_object", "emergency_stop"\n        ]\n        self.logger = logging.getLogger(__name__)\n\n    def add_safety_constraints(self, plan: List[PlanStep]) -> List[PlanStep]:\n        """Add safety checks to each step of the plan"""\n        enhanced_plan = []\n\n        for i, step in enumerate(plan):\n            # Add safety check before critical actions\n            if step.action in ["navigate_to", "pick_object", "place_object"]:\n                # Add sensor check before action\n                sensor_check = PlanStep(\n                    action="inspect",\n                    parameters={"target": step.parameters.get("location", step.parameters.get("object"))},\n                    description=f"Verify environment is safe before {step.action}",\n                    dependencies=step.dependencies[:],  # Copy dependencies\n                    estimated_duration=0.5\n                )\n                enhanced_plan.append(sensor_check)\n\n            # Add the original step\n            enhanced_plan.append(step)\n\n            # Add verification step after critical actions\n            if step.action in ["grasp", "place_object", "navigate_to"]:\n                verification = PlanStep(\n                    action="inspect",\n                    parameters={"target": step.parameters.get("object", step.parameters.get("location"))},\n                    description=f"Verify successful completion of {step.action}",\n                    dependencies=[step.action],  # Depends on the previous step\n                    estimated_duration=0.5\n                )\n                enhanced_plan.append(verification)\n\n        return enhanced_plan\n\n    def create_recovery_plan(self, failed_step: PlanStep, error_type: str) -> List[PlanStep]:\n        """Create a recovery plan for a failed step"""\n        recovery_steps = []\n\n        if error_type == "object_not_found":\n            # Search for the object in nearby locations\n            recovery_steps.extend([\n                PlanStep(\n                    action="inspect",\n                    parameters={"search_area": "nearby"},\n                    description="Search for object in nearby locations",\n                    dependencies=[],\n                    estimated_duration=2.0\n                ),\n                PlanStep(\n                    action=failed_step.action,\n                    parameters=failed_step.parameters,\n                    description=f"Retry {failed_step.action} with updated object location",\n                    dependencies=["inspect"],\n                    estimated_duration=failed_step.estimated_duration\n                )\n            ])\n        elif error_type == "collision_detected":\n            # Plan alternative route\n            recovery_steps.extend([\n                PlanStep(\n                    action="navigate_to",\n                    parameters={"location": "safe_position", "avoid_obstacles": True},\n                    description="Move to safe position to avoid collision",\n                    dependencies=[],\n                    estimated_duration=1.5\n                ),\n                PlanStep(\n                    action=failed_step.action,\n                    parameters=failed_step.parameters,\n                    description=f"Retry {failed_step.action} with collision avoidance",\n                    dependencies=["navigate_to"],\n                    estimated_duration=failed_step.estimated_duration\n                )\n            ])\n        elif error_type == "grasp_failed":\n            # Try alternative grasp strategy\n            recovery_steps.extend([\n                PlanStep(\n                    action="adjust_gripper",\n                    parameters={"width": "wider"},\n                    description="Adjust gripper for wider grasp",\n                    dependencies=[],\n                    estimated_duration=0.5\n                ),\n                PlanStep(\n                    action=failed_step.action,\n                    parameters=failed_step.parameters,\n                    description=f"Retry {failed_step.action} with adjusted gripper",\n                    dependencies=["adjust_gripper"],\n                    estimated_duration=failed_step.estimated_duration\n                )\n            ])\n        else:\n            # General recovery - wait and retry\n            recovery_steps.extend([\n                PlanStep(\n                    action="wait",\n                    parameters={"duration": 1.0},\n                    description="Wait before retrying failed action",\n                    dependencies=[],\n                    estimated_duration=1.0\n                ),\n                PlanStep(\n                    action=failed_step.action,\n                    parameters=failed_step.parameters,\n                    description=f"Retry {failed_step.action}",\n                    dependencies=["wait"],\n                    estimated_duration=failed_step.estimated_duration\n                )\n            ])\n\n        return recovery_steps\n\n    async def plan_with_safety(self, command: str, environment_state: Dict[str, Any]) -> Dict[str, Any]:\n        """Plan with safety checks and recovery options"""\n        # Generate initial plan\n        result = await self.contextual_planner.generate_contextual_plan(\n            command, self.robot_capabilities, environment_state\n        )\n\n        if not result.success:\n            return {\n                "success": False,\n                "error": result.error,\n                "safety_enhanced_plan": [],\n                "recovery_options": {}\n            }\n\n        # Add safety constraints\n        safety_enhanced_plan = self.add_safety_constraints(result.plan)\n\n        # Validate the enhanced plan\n        is_valid, errors = self.contextual_planner.validator.validate_for_execution(\n            safety_enhanced_plan, environment_state\n        )\n\n        if not is_valid:\n            return {\n                "success": False,\n                "error": f"Enhanced plan validation failed: {errors}",\n                "safety_enhanced_plan": [],\n                "recovery_options": {}\n            }\n\n        # Generate recovery options for each step\n        recovery_options = {}\n        for step in safety_enhanced_plan:\n            if step.action in ["navigate_to", "pick_object", "grasp", "place_object"]:\n                # Common failure modes for these actions\n                recovery_options[step.action] = {\n                    "object_not_found": self.create_recovery_plan(step, "object_not_found"),\n                    "collision_detected": self.create_recovery_plan(step, "collision_detected"),\n                    "grasp_failed": self.create_recovery_plan(step, "grasp_failed"),\n                    "general_failure": self.create_recovery_plan(step, "general")\n                }\n\n        return {\n            "success": True,\n            "original_plan": [s.__dict__ for s in result.plan],\n            "safety_enhanced_plan": [s.__dict__ for s in safety_enhanced_plan],\n            "recovery_options": recovery_options,\n            "estimated_duration": sum(s.estimated_duration for s in safety_enhanced_plan),\n            "confidence": result.confidence\n        }\n\n    async def simulate_execution_with_recovery(self, command: str, environment_state: Dict[str, Any]) -> Dict[str, Any]:\n        """Simulate execution with potential failures and recovery"""\n        # Plan with safety\n        plan_result = await self.plan_with_safety(command, environment_state)\n\n        if not plan_result["success"]:\n            return plan_result\n\n        # Simulate execution (in a real system, this would interface with the robot)\n        execution_log = []\n        current_step = 0\n        total_time = 0\n\n        for step in plan_result["safety_enhanced_plan"]:\n            execution_log.append({\n                "step": step,\n                "status": "executing",\n                "timestamp": time.time()\n            })\n\n            # Simulate step execution time\n            await asyncio.sleep(step.get("estimated_duration", 0.1))\n            total_time += step.get("estimated_duration", 0.1)\n\n            # Simulate potential failure for critical actions\n            if step["action"] in ["navigate_to", "pick_object"] and current_step % 3 == 2:\n                # Simulate a failure every 3rd critical action\n                execution_log[-1]["status"] = "failed"\n                execution_log[-1]["error"] = "object_not_found"\n\n                # Apply recovery\n                recovery_plan = plan_result["recovery_options"].get(step["action"], {}).get("object_not_found", [])\n                if recovery_plan:\n                    execution_log.append({\n                        "step": "recovery",\n                        "recovery_plan": [r.__dict__ for r in recovery_plan],\n                        "status": "applying_recovery",\n                        "timestamp": time.time()\n                    })\n\n                    # Simulate recovery execution\n                    for recovery_step in recovery_plan:\n                        await asyncio.sleep(recovery_step.estimated_duration)\n                        total_time += recovery_step.estimated_duration\n\n                    execution_log.append({\n                        "step": "recovery",\n                        "status": "recovery_successful",\n                        "timestamp": time.time()\n                    })\n\n            else:\n                execution_log[-1]["status"] = "completed"\n\n            current_step += 1\n\n        return {\n            "execution_log": execution_log,\n            "total_time": total_time,\n            "final_status": "completed_with_recovery" if any(log.get("status") == "applying_recovery" for log in execution_log) else "completed_successfully"\n        }\n\ndef main():\n    """Main function for safe planning demonstration"""\n    print("Initializing Safe Planning System...")\n\n    # In a real implementation, you would provide an API key\n    # For this example, we\'ll just demonstrate the structure\n    print("Safe planning system initialized with safety checks and recovery mechanisms.")\n    print("The system includes:")\n    print("- Safety constraints added to critical actions")\n    print("- Recovery plans for common failure modes")\n    print("- Real-time monitoring and adaptation capabilities")\n    print("- Comprehensive error handling and fallback strategies")\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,i.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(e.p,{children:"LLM-based task planning represents a significant advancement in robotics, enabling natural language interaction with complex robotic systems. Key aspects include:"}),"\n",(0,i.jsxs)(e.ul,{children:["\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Natural Language Interface"}),": Users can express complex tasks in plain English"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Intelligent Decomposition"}),": LLMs break down high-level goals into executable steps"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Context Awareness"}),": Planning considers environment state and past experiences"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Safety Integration"}),": Built-in safety checks and recovery mechanisms"]}),"\n",(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:"Adaptive Learning"}),": Systems improve over time through experience"]}),"\n"]}),"\n",(0,i.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsx)(e.h3,{id:"conceptual",children:"Conceptual"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Compare the advantages and limitations of LLM-based planning versus classical planning algorithms (e.g., PDDL, STRIPS) for robotics applications. When would you choose one approach over the other?"}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"logical",children:"Logical"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:'Design a planning system that can handle ambiguous commands (e.g., "clean the room" when the specific objects and cleaning methods are not specified). How would your system determine the appropriate level of detail and specific actions?'}),"\n"]}),"\n",(0,i.jsx)(e.h3,{id:"implementation-1",children:"Implementation"}),"\n",(0,i.jsxs)(e.ol,{children:["\n",(0,i.jsx)(e.li,{children:"Implement an LLM-based planning system that integrates with ROS 2 action servers, including proper error handling, safety validation, and plan adaptation based on execution feedback."}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(p,{...n})}):p(n)}},8453(n,e,t){t.d(e,{R:()=>o,x:()=>r});var a=t(6540);const i={},s=a.createContext(i);function o(n){const e=a.useContext(s);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:o(n.components),a.createElement(s.Provider,{value:e},n.children)}}}]);