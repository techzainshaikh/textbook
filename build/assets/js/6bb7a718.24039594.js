"use strict";(globalThis.webpackChunkphysical_ai_book_humanoid=globalThis.webpackChunkphysical_ai_book_humanoid||[]).push([[1193],{367(n,e,i){i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-digital-twin/chapter-4-unity-visualization","title":"Unity Visualization for Human-Robot Interaction","description":"Creating immersive visualization environments for robotics using Unity","source":"@site/docs/module-2-digital-twin/chapter-4-unity-visualization.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/chapter-4-unity-visualization","permalink":"/textbook/docs/module-2-digital-twin/chapter-4-unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/Panaversity/physical_ai_book_humanoid/tree/main/docs/module-2-digital-twin/chapter-4-unity-visualization.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Unity Visualization for Human-Robot Interaction","sidebar_position":5,"description":"Creating immersive visualization environments for robotics using Unity","keywords":["unity","visualization","human-robot interaction","3d graphics","robotics simulation"]},"sidebar":"tutorialSidebar","previous":{"title":"Environment Modeling for Digital Twins","permalink":"/textbook/docs/module-2-digital-twin/chapter-3-environment-modeling"},"next":{"title":"Capstone Project - Complete Physical AI System Integration","permalink":"/textbook/docs/module-2-digital-twin/chapter-4-capstone-integration"}}');var o=i(4848),a=i(8453);const r={title:"Unity Visualization for Human-Robot Interaction",sidebar_position:5,description:"Creating immersive visualization environments for robotics using Unity",keywords:["unity","visualization","human-robot interaction","3d graphics","robotics simulation"]},s="Chapter 4: Unity Visualization for Human-Robot Interaction",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Core Concepts",id:"core-concepts",level:2},{value:"Key Visualization Components",id:"key-visualization-components",level:3},{value:"Unity-ROS Integration",id:"unity-ros-integration",level:3},{value:"Implementation",id:"implementation",level:2},{value:"Unity Project Setup",id:"unity-project-setup",level:3},{value:"Basic Robot Controller Script",id:"basic-robot-controller-script",level:3},{value:"ROS Connection Manager",id:"ros-connection-manager",level:3},{value:"Human-Robot Interaction Interface",id:"human-robot-interaction-interface",level:3},{value:"Examples",id:"examples",level:2},{value:"Example 1: Robot State Visualization System",id:"example-1-robot-state-visualization-system",level:3},{value:"Example 2: Scene Manager for Multi-Environment Support",id:"example-2-scene-manager-for-multi-environment-support",level:3},{value:"Summary",id:"summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Conceptual",id:"conceptual",level:3},{value:"Logical",id:"logical",level:3},{value:"Implementation",id:"implementation-1",level:3}];function u(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"chapter-4-unity-visualization-for-human-robot-interaction",children:"Chapter 4: Unity Visualization for Human-Robot Interaction"})}),"\n",(0,o.jsx)(e.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(e.p,{children:"By the end of this chapter, students will be able to:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Set up Unity projects for robotics visualization and human-robot interaction prototyping"}),"\n",(0,o.jsx)(e.li,{children:"Implement realistic 3D rendering of humanoid robots with proper physics properties"}),"\n",(0,o.jsx)(e.li,{children:"Create interactive interfaces for commanding and monitoring robot behavior"}),"\n",(0,o.jsx)(e.li,{children:"Integrate Unity visualization with ROS 2 for real-time robot state display"}),"\n",(0,o.jsx)(e.li,{children:"Design user experiences that facilitate effective human-robot collaboration"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(e.p,{children:"Students should have:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Basic understanding of 3D graphics concepts (vertices, meshes, materials, lighting)"}),"\n",(0,o.jsx)(e.li,{children:"Familiarity with C# programming (Unity's primary scripting language)"}),"\n",(0,o.jsx)(e.li,{children:"Understanding of human-robot interaction principles"}),"\n",(0,o.jsx)(e.li,{children:"Completion of previous chapters on physics simulation and sensor modeling"}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"core-concepts",children:"Core Concepts"}),"\n",(0,o.jsx)(e.p,{children:"Unity provides high-fidelity visualization capabilities that complement Gazebo's physics simulation. While Gazebo excels at accurate physics modeling, Unity excels at photorealistic rendering and human-robot interaction design."}),"\n",(0,o.jsx)(e.h3,{id:"key-visualization-components",children:"Key Visualization Components"}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Robot Visualization:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Accurate 3D models matching physical robot specifications"}),"\n",(0,o.jsx)(e.li,{children:"Proper joint constraints and kinematic chains"}),"\n",(0,o.jsx)(e.li,{children:"Realistic materials and textures"}),"\n",(0,o.jsx)(e.li,{children:"Animation systems for smooth motion representation"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Scene Design:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Environment modeling with accurate lighting and materials"}),"\n",(0,o.jsx)(e.li,{children:"Occlusion and collision detection for realistic interaction"}),"\n",(0,o.jsx)(e.li,{children:"Level of detail (LOD) systems for performance optimization"}),"\n",(0,o.jsx)(e.li,{children:"Asset optimization for real-time rendering"}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:(0,o.jsx)(e.strong,{children:"Human-Robot Interface:"})}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsx)(e.li,{children:"Command interfaces for robot control"}),"\n",(0,o.jsx)(e.li,{children:"Status displays for robot state visualization"}),"\n",(0,o.jsx)(e.li,{children:"Interactive elements for teleoperation"}),"\n",(0,o.jsx)(e.li,{children:"Augmented reality overlays for enhanced situational awareness"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"unity-ros-integration",children:"Unity-ROS Integration"}),"\n",(0,o.jsx)(e.p,{children:"Unity can connect to ROS 2 systems through several methods:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Unity ROS TCP Connector"}),": Direct TCP/IP communication"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS#"}),": C# implementation of ROS protocols"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"WebSocket bridges"}),": For web-based deployments"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Custom middleware"}),": For specialized applications"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"implementation",children:"Implementation"}),"\n",(0,o.jsx)(e.p,{children:"Let's implement a Unity visualization system for our humanoid robot. We'll create a basic scene structure with robot visualization and ROS 2 integration."}),"\n",(0,o.jsx)(e.h3,{id:"unity-project-setup",children:"Unity Project Setup"}),"\n",(0,o.jsx)(e.p,{children:"First, let's outline the basic Unity project structure for robotics visualization:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"UnityHumanoidVisualization/\n\u251c\u2500\u2500 Assets/\n\u2502   \u251c\u2500\u2500 Scripts/\n\u2502   \u2502   \u251c\u2500\u2500 RobotController.cs          # Handles robot state updates\n\u2502   \u2502   \u251c\u2500\u2500 ROSConnectionManager.cs      # Manages ROS communication\n\u2502   \u2502   \u251c\u2500\u2500 JointVisualizer.cs          # Updates joint positions\n\u2502   \u2502   \u2514\u2500\u2500 HRIInterface.cs             # Human-robot interaction elements\n\u2502   \u251c\u2500\u2500 Models/\n\u2502   \u2502   \u251c\u2500\u2500 HumanoidRobot/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Robot.prefab            # Robot prefab with joints\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 Materials/              # Robot materials\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 Meshes/                 # Individual robot parts\n\u2502   \u2502   \u2514\u2500\u2500 Environments/\n\u2502   \u2502       \u251c\u2500\u2500 Indoor/\n\u2502   \u2502       \u2514\u2500\u2500 Outdoor/\n\u2502   \u251c\u2500\u2500 Scenes/\n\u2502   \u2502   \u2514\u2500\u2500 MainScene.unity\n\u2502   \u251c\u2500\u2500 Materials/\n\u2502   \u2502   \u251c\u2500\u2500 RobotMaterials/\n\u2502   \u2502   \u2514\u2500\u2500 EnvironmentMaterials/\n\u2502   \u251c\u2500\u2500 Plugins/\n\u2502   \u2502   \u2514\u2500\u2500 ROSBridgeLib/               # ROS communication library\n\u2502   \u2514\u2500\u2500 Prefabs/\n\u2502       \u251c\u2500\u2500 Robot.prefab\n\u2502       \u2514\u2500\u2500 SensorVisualizers/\n\u251c\u2500\u2500 ProjectSettings/\n\u2514\u2500\u2500 Packages/\n"})}),"\n",(0,o.jsx)(e.h3,{id:"basic-robot-controller-script",children:"Basic Robot Controller Script"}),"\n",(0,o.jsx)(e.p,{children:"Here's a Unity C# script to handle robot state visualization:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\n\npublic class RobotController : MonoBehaviour\n{\n    [Header("Robot Configuration")]\n    public string robotName = "HumanoidRobot";\n    public float visualizationScale = 1.0f;\n\n    [Header("Joint Mapping")]\n    public Dictionary<string, Transform> jointMap = new Dictionary<string, Transform>();\n\n    [Header("State Visualization")]\n    public Material activeMaterial;      // For active joints\n    public Material idleMaterial;        // For inactive joints\n    public Color stateColor = Color.green;\n\n    // Robot state data received from ROS\n    private Dictionary<string, float> jointPositions = new Dictionary<string, float>();\n    private Vector3 robotPosition;\n    private Quaternion robotRotation;\n\n    void Start()\n    {\n        InitializeJointMap();\n        robotPosition = transform.position;\n        robotRotation = transform.rotation;\n    }\n\n    /// <summary>\n    /// Initialize the mapping between ROS joint names and Unity transforms\n    /// </summary>\n    private void InitializeJointMap()\n    {\n        // Find all joint transforms under the robot hierarchy\n        Transform[] allChildren = GetComponentsInChildren<Transform>();\n\n        foreach (Transform child in allChildren)\n        {\n            if (child.name.ToLower().Contains("joint") ||\n                child.name.ToLower().Contains("link"))\n            {\n                jointMap[child.name] = child;\n\n                // Initialize joint positions to zero\n                jointPositions[child.name] = 0.0f;\n            }\n        }\n\n        Debug.Log($"Initialized {jointMap.Count} joints for robot {robotName}");\n    }\n\n    /// <summary>\n    /// Update robot state from ROS data\n    /// </summary>\n    public void UpdateRobotState(Dictionary<string, float> positions,\n                                Vector3 position, Quaternion rotation)\n    {\n        // Update joint positions\n        foreach (var kvp in positions)\n        {\n            if (jointMap.ContainsKey(kvp.Key))\n            {\n                jointPositions[kvp.Key] = kvp.Value;\n            }\n        }\n\n        // Update robot position and rotation\n        robotPosition = position;\n        robotRotation = rotation;\n\n        // Apply changes in LateUpdate for smooth animation\n    }\n\n    void LateUpdate()\n    {\n        // Update joint positions based on stored values\n        foreach (var kvp in jointPositions)\n        {\n            if (jointMap.ContainsKey(kvp.Key))\n            {\n                Transform jointTransform = jointMap[kvp.Key];\n\n                // Apply rotation to the joint\n                // Note: This is a simplified example - real implementation would depend on joint type\n                jointTransform.localRotation = Quaternion.Euler(0, 0, kvp.Value * Mathf.Rad2Deg);\n            }\n        }\n\n        // Update robot position and rotation\n        transform.position = robotPosition * visualizationScale;\n        transform.rotation = robotRotation;\n    }\n\n    /// <summary>\n    /// Highlight active joints\n    /// </summary>\n    public void SetJointActivity(string jointName, bool isActive)\n    {\n        if (jointMap.ContainsKey(jointName))\n        {\n            Renderer renderer = jointMap[jointName].GetComponent<Renderer>();\n            if (renderer != null)\n            {\n                renderer.material = isActive ? activeMaterial : idleMaterial;\n            }\n        }\n    }\n\n    /// <summary>\n    /// Visualize sensor data as overlays\n    /// </summary>\n    public void VisualizeSensorData(string sensorType, float[] sensorValues)\n    {\n        switch (sensorType)\n        {\n            case "lidar":\n                VisualizeLidarData(sensorValues);\n                break;\n            case "imu":\n                VisualizeIMUData(sensorValues);\n                break;\n            case "camera":\n                // Camera visualization would require texture updates\n                break;\n        }\n    }\n\n    private void VisualizeLidarData(float[] ranges)\n    {\n        // Create visualization for LiDAR data\n        // This could involve creating point clouds or ray visualizations\n        Debug.Log($"Visualizing LiDAR data with {ranges.Length} range measurements");\n    }\n\n    private void VisualizeIMUData(float[] values)\n    {\n        // Visualize IMU orientation and acceleration data\n        Debug.Log($"Visualizing IMU data: [{values[0]}, {values[1]}, {values[2]}]");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"ros-connection-manager",children:"ROS Connection Manager"}),"\n",(0,o.jsx)(e.p,{children:"Now let's implement the ROS connection manager:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing RosSharp.RosBridgeClient;\nusing RosSharp.Messages.Sensor;\nusing RosSharp.Messages.Geometry;\nusing RosSharp.Messages.Nav;\nusing System.Collections.Generic;\n\npublic class ROSConnectionManager : MonoBehaviour\n{\n    [Header("Connection Settings")]\n    public string rosBridgeServerUrl = "ws://127.0.0.1:9090";\n\n    [Header("Robot Topics")]\n    public string jointStatesTopic = "/humanoid/joint_states";\n    public string cmdVelTopic = "/humanoid/cmd_vel";\n    public string laserScanTopic = "/humanoid/scan";\n    public string imuTopic = "/humanoid/imu/data";\n\n    [Header("References")]\n    public RobotController robotController;\n\n    private RosSocket rosSocket;\n    private JointStateSubscriber jointStateSubscriber;\n    private TwistPublisher cmdVelPublisher;\n    private LaserScanSubscriber laserScanSubscriber;\n    private ImuSubscriber imuSubscriber;\n\n    void Start()\n    {\n        ConnectToROSBridge();\n        SubscribeToTopics();\n    }\n\n    void ConnectToROSBridge()\n    {\n        WebSocketProtocols webSocketProtocol = WebSocketProtocols.GetProtocol(WebSocketProtocolType.Native);\n\n        RosBridgeClient.Protocols.IProtocol protocol = new RosBridgeClient.Protocols.WebSocketNetProtocol(\n            rosBridgeServerUrl, webSocketProtocol);\n\n        rosSocket = new RosSocket(protocol);\n\n        Debug.Log($"Connecting to ROS Bridge at {rosBridgeServerUrl}");\n    }\n\n    void SubscribeToTopics()\n    {\n        // Subscribe to joint states\n        jointStateSubscriber = rosSocket.Subscribe<JointState>(jointStatesTopic, JointStateCallback);\n\n        // Subscribe to laser scan\n        laserScanSubscriber = rosSocket.Subscribe<LaserScan>(laserScanTopic, LaserScanCallback);\n\n        // Subscribe to IMU data\n        imuSubscriber = rosSocket.Subscribe<Imu>(imuTopic, ImuCallback);\n\n        Debug.Log("Subscribed to ROS topics");\n    }\n\n    void JointStateCallback(JointState jointState)\n    {\n        if (robotController == null) return;\n\n        // Convert ROS joint states to Unity format\n        Dictionary<string, float> jointPositions = new Dictionary<string, float>();\n\n        for (int i = 0; i < jointState.name.Count; i++)\n        {\n            if (i < jointState.position.Count)\n            {\n                jointPositions[jointState.name[i]] = (float)jointState.position[i];\n            }\n        }\n\n        // For now, use identity position and rotation\n        // In a real implementation, you\'d get this from odometry\n        Vector3 position = Vector3.zero;\n        Quaternion rotation = Quaternion.identity;\n\n        robotController.UpdateRobotState(jointPositions, position, rotation);\n    }\n\n    void LaserScanCallback(LaserScan scan)\n    {\n        if (robotController == null) return;\n\n        // Convert ROS LaserScan to float array\n        float[] ranges = new float[scan.ranges.Count];\n        for (int i = 0; i < scan.ranges.Count; i++)\n        {\n            ranges[i] = (float)scan.ranges[i];\n        }\n\n        robotController.VisualizeSensorData("lidar", ranges);\n    }\n\n    void ImuCallback(Imu imu)\n    {\n        if (robotController == null) return;\n\n        // Extract orientation and angular velocity\n        float[] imuValues = new float[6];\n        imuValues[0] = (float)imu.orientation.x;\n        imuValues[1] = (float)imu.orientation.y;\n        imuValues[2] = (float)imu.orientation.z;\n        imuValues[3] = (float)imu.angular_velocity.x;\n        imuValues[4] = (float)imu.angular_velocity.y;\n        imuValues[5] = (float)imu.angular_velocity.z;\n\n        robotController.VisualizeSensorData("imu", imuValues);\n    }\n\n    /// <summary>\n    /// Send velocity command to robot\n    /// </summary>\n    public void SendVelocityCommand(float linearX, float angularZ)\n    {\n        if (cmdVelPublisher == null)\n        {\n            cmdVelPublisher = rosSocket.Advertise<Twist>(cmdVelTopic);\n        }\n\n        Twist cmd = new Twist();\n        cmd.linear = new Vector3Msg(linearX, 0, 0);\n        cmd.angular = new Vector3Msg(0, 0, angularZ);\n\n        cmdVelPublisher.Publish(cmd);\n    }\n\n    void OnDestroy()\n    {\n        if (rosSocket != null)\n        {\n            rosSocket.Close();\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"human-robot-interaction-interface",children:"Human-Robot Interaction Interface"}),"\n",(0,o.jsx)(e.p,{children:"Let's create a UI for human-robot interaction:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.UI;\nusing TMPro;\n\npublic class HRIInterface : MonoBehaviour\n{\n    [Header("UI References")]\n    public Slider linearVelocitySlider;\n    public Slider angularVelocitySlider;\n    public Button forwardButton;\n    public Button backwardButton;\n    public Button leftButton;\n    public Button rightButton;\n    public Button stopButton;\n    public TextMeshProUGUI statusText;\n    public TextMeshProUGUI jointInfoText;\n\n    [Header("Robot Control")]\n    public ROSConnectionManager rosManager;\n    public RobotController robotController;\n\n    [Header("Control Parameters")]\n    public float maxLinearVelocity = 1.0f;\n    public float maxAngularVelocity = 1.0f;\n    public float controlUpdateInterval = 0.1f;\n\n    private float lastControlUpdate = 0f;\n\n    void Start()\n    {\n        SetupUIEvents();\n        UpdateStatusDisplay();\n    }\n\n    void Update()\n    {\n        // Update status display periodically\n        if (Time.time - lastControlUpdate > controlUpdateInterval)\n        {\n            UpdateStatusDisplay();\n            lastControlUpdate = Time.time;\n        }\n    }\n\n    void SetupUIEvents()\n    {\n        // Velocity sliders\n        if (linearVelocitySlider != null)\n        {\n            linearVelocitySlider.onValueChanged.AddListener(OnLinearVelocityChanged);\n        }\n\n        if (angularVelocitySlider != null)\n        {\n            angularVelocitySlider.onValueChanged.AddListener(OnAngularVelocityChanged);\n        }\n\n        // Direction buttons\n        if (forwardButton != null)\n        {\n            forwardButton.onClick.AddListener(() => MoveRobot(1, 0));\n        }\n\n        if (backwardButton != null)\n        {\n            backwardButton.onClick.AddListener(() => MoveRobot(-1, 0));\n        }\n\n        if (leftButton != null)\n        {\n            leftButton.onClick.AddListener(() => MoveRobot(0, 1));\n        }\n\n        if (rightButton != null)\n        {\n            rightButton.onClick.AddListener(() => MoveRobot(0, -1));\n        }\n\n        if (stopButton != null)\n        {\n            stopButton.onClick.AddListener(() => MoveRobot(0, 0));\n        }\n    }\n\n    void OnLinearVelocityChanged(float value)\n    {\n        float linearVel = value * maxLinearVelocity;\n        SendVelocityCommand(linearVel, angularVelocitySlider.value * maxAngularVelocity);\n    }\n\n    void OnAngularVelocityChanged(float value)\n    {\n        float angularVel = value * maxAngularVelocity;\n        SendVelocityCommand(linearVelocitySlider.value * maxLinearVelocity, angularVel);\n    }\n\n    void MoveRobot(int linearDir, int angularDir)\n    {\n        float linearVel = linearDir * maxLinearVelocity;\n        float angularVel = angularDir * maxAngularVelocity;\n\n        SendVelocityCommand(linearVel, angularVel);\n    }\n\n    void SendVelocityCommand(float linearX, float angularZ)\n    {\n        if (rosManager != null)\n        {\n            rosManager.SendVelocityCommand(linearX, angularZ);\n\n            // Update status text\n            statusText.text = $"Linear: {linearX:F2}, Angular: {angularZ:F2}";\n        }\n    }\n\n    void UpdateStatusDisplay()\n    {\n        if (statusText != null)\n        {\n            statusText.text = $"ROS Connected: {(rosManager != null ? "YES" : "NO")}\\n" +\n                             $"Robot Active: {(robotController != null ? "YES" : "NO")}";\n        }\n\n        if (jointInfoText != null && robotController != null)\n        {\n            // Display information about active joints\n            jointInfoText.text = "Active Joints: " + robotController.GetActiveJointCount();\n        }\n    }\n\n    /// <summary>\n    /// Send custom command to robot\n    /// </summary>\n    public void SendCustomCommand(string command)\n    {\n        // This would be implemented based on specific robot capabilities\n        Debug.Log($"Sending custom command: {command}");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"examples",children:"Examples"}),"\n",(0,o.jsx)(e.h3,{id:"example-1-robot-state-visualization-system",children:"Example 1: Robot State Visualization System"}),"\n",(0,o.jsx)(e.p,{children:"Let's create a comprehensive robot state visualization system:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing System.Collections.Generic;\nusing System.Linq;\n\npublic class RobotStateVisualizer : MonoBehaviour\n{\n    [Header("Visualization Settings")]\n    public GameObject robotModel;\n    public Material defaultMaterial;\n    public Material alertMaterial;\n    public Material warningMaterial;\n\n    [Header("Sensor Visualization")]\n    public GameObject lidarPointCloudPrefab;\n    public GameObject cameraFrustumPrefab;\n    public GameObject pathVisualizerPrefab;\n\n    [Header("UI Overlay")]\n    public GameObject sensorOverlay;\n    public GameObject statusOverlay;\n\n    private Dictionary<string, GameObject> sensorVisualizers = new Dictionary<string, GameObject>();\n    private Dictionary<string, Material> originalMaterials = new Dictionary<string, Material>();\n\n    void Start()\n    {\n        SetupRobotMaterials();\n        InitializeSensorVisualizers();\n    }\n\n    void SetupRobotMaterials()\n    {\n        // Store original materials for restoration\n        Renderer[] renderers = robotModel.GetComponentsInChildren<Renderer>();\n\n        foreach (Renderer renderer in renderers)\n        {\n            originalMaterials[renderer.name] = renderer.sharedMaterial;\n        }\n    }\n\n    void InitializeSensorVisualizers()\n    {\n        // Create visualizers for different sensor types\n        if (lidarPointCloudPrefab != null)\n        {\n            GameObject lidarVis = Instantiate(lidarPointCloudPrefab, robotModel.transform);\n            sensorVisualizers["lidar"] = lidarVis;\n            lidarVis.SetActive(false);\n        }\n\n        if (cameraFrustumPrefab != null)\n        {\n            GameObject camVis = Instantiate(cameraFrustumPrefab, robotModel.transform);\n            sensorVisualizers["camera"] = camVis;\n            camVis.SetActive(false);\n        }\n\n        if (pathVisualizerPrefab != null)\n        {\n            GameObject pathVis = Instantiate(pathVisualizerPrefab, robotModel.transform);\n            sensorVisualizers["path"] = pathVis;\n            pathVis.SetActive(false);\n        }\n    }\n\n    /// <summary>\n    /// Update robot state visualization based on health indicators\n    /// </summary>\n    public void UpdateRobotHealthVisualization(Dictionary<string, float> healthMetrics)\n    {\n        foreach (var metric in healthMetrics)\n        {\n            string componentName = metric.Key;\n            float healthLevel = metric.Value; // 0.0 to 1.0\n\n            // Update material based on health\n            if (originalMaterials.ContainsKey(componentName))\n            {\n                Renderer compRenderer = GetRendererByName(componentName);\n                if (compRenderer != null)\n                {\n                    if (healthLevel < 0.3f)\n                    {\n                        compRenderer.sharedMaterial = alertMaterial; // Critical\n                    }\n                    else if (healthLevel < 0.7f)\n                    {\n                        compRenderer.sharedMaterial = warningMaterial; // Warning\n                    }\n                    else\n                    {\n                        compRenderer.sharedMaterial = originalMaterials[componentName]; // Normal\n                    }\n                }\n            }\n        }\n    }\n\n    /// <summary>\n    /// Visualize sensor data overlay\n    /// </summary>\n    public void VisualizeSensorData(string sensorType, object sensorData)\n    {\n        if (!sensorVisualizers.ContainsKey(sensorType))\n            return;\n\n        GameObject visObject = sensorVisualizers[sensorType];\n        visObject.SetActive(true);\n\n        switch (sensorType)\n        {\n            case "lidar":\n                UpdateLidarVisualization((float[])sensorData);\n                break;\n            case "camera":\n                UpdateCameraVisualization((Texture2D)sensorData);\n                break;\n            case "imu":\n                UpdateIMUVisualization((Vector3)sensorData);\n                break;\n        }\n    }\n\n    void UpdateLidarVisualization(float[] ranges)\n    {\n        if (!sensorVisualizers.ContainsKey("lidar")) return;\n\n        GameObject lidarVis = sensorVisualizers["lidar"];\n\n        // In a real implementation, this would update a point cloud or ray visualization\n        Debug.Log($"Updating LiDAR visualization with {ranges.Length} points");\n\n        // Example: Create simple ray visualization\n        LineRenderer lineRenderer = lidarVis.GetComponent<LineRenderer>();\n        if (lineRenderer != null)\n        {\n            lineRenderer.positionCount = ranges.Length;\n\n            for (int i = 0; i < ranges.Length; i++)\n            {\n                float angle = (float)i / ranges.Length * 2 * Mathf.PI;\n                float range = ranges[i];\n\n                if (float.IsNaN(range) || float.IsInfinity(range))\n                    range = 0; // Skip invalid measurements\n\n                Vector3 point = new Vector3(\n                    Mathf.Cos(angle) * range,\n                    0,\n                    Mathf.Sin(angle) * range\n                );\n\n                lineRenderer.SetPosition(i, point);\n            }\n        }\n    }\n\n    void UpdateCameraVisualization(Texture2D cameraImage)\n    {\n        // Update camera frustum or overlay with the camera image\n        Debug.Log("Updating camera visualization");\n    }\n\n    void UpdateIMUVisualization(Vector3 orientation)\n    {\n        // Update IMU visualization based on orientation data\n        Debug.Log($"Updating IMU visualization: {orientation}");\n    }\n\n    Renderer GetRendererByName(string name)\n    {\n        Renderer[] renderers = robotModel.GetComponentsInChildren<Renderer>();\n        return renderers.FirstOrDefault(r => r.name == name);\n    }\n\n    /// <summary>\n    /// Toggle sensor visualization\n    /// </summary>\n    public void ToggleSensorVisualization(string sensorType, bool visible)\n    {\n        if (sensorVisualizers.ContainsKey(sensorType))\n        {\n            sensorVisualizers[sensorType].SetActive(visible);\n        }\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h3,{id:"example-2-scene-manager-for-multi-environment-support",children:"Example 2: Scene Manager for Multi-Environment Support"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing UnityEngine.SceneManagement;\nusing System.Collections;\nusing System.Collections.Generic;\n\npublic class EnvironmentSceneManager : MonoBehaviour\n{\n    [Header("Environment Presets")]\n    public EnvironmentPreset[] environmentPresets;\n\n    [Header("Robot Spawn Points")]\n    public Transform[] spawnPoints;\n\n    [Header("Lighting Settings")]\n    public Light sunLight;\n    public AnimationCurve dayNightCycle;\n\n    [Header("Weather Effects")]\n    public ParticleSystem rainEffect;\n    public ParticleSystem fogEffect;\n\n    private int currentPresetIndex = 0;\n    private float dayNightTimer = 0f;\n    private bool isDayNightActive = false;\n\n    [System.Serializable]\n    public class EnvironmentPreset\n    {\n        public string presetName;\n        public Color ambientColor;\n        public Color skyColor;\n        public float sunIntensity;\n        public Vector3 sunDirection;\n        public bool enableRain;\n        public bool enableFog;\n        public float windSpeed;\n    }\n\n    void Start()\n    {\n        // Initialize with first environment preset\n        if (environmentPresets.Length > 0)\n        {\n            ApplyEnvironmentPreset(environmentPresets[0]);\n        }\n    }\n\n    /// <summary>\n    /// Apply an environment preset\n    /// </summary>\n    public void ApplyEnvironmentPreset(EnvironmentPreset preset)\n    {\n        // Apply ambient lighting\n        RenderSettings.ambientLight = preset.ambientColor;\n\n        // Apply skybox colors (assuming procedural skybox)\n        if (RenderSettings.skybox != null)\n        {\n            RenderSettings.skybox.SetColor("_SkyTint", preset.skyColor);\n        }\n\n        // Apply sun light settings\n        if (sunLight != null)\n        {\n            sunLight.intensity = preset.sunIntensity;\n            sunLight.transform.eulerAngles = preset.sunDirection;\n        }\n\n        // Enable/disable weather effects\n        if (rainEffect != null)\n        {\n            rainEffect.gameObject.SetActive(preset.enableRain);\n            var emission = rainEffect.emission;\n            emission.enabled = preset.enableRain;\n        }\n\n        if (fogEffect != null)\n        {\n            fogEffect.gameObject.SetActive(preset.enableFog);\n            var emission = fogEffect.emission;\n            emission.enabled = preset.enableFog;\n        }\n\n        // Apply wind settings if using a wind system\n        ApplyWindSettings(preset.windSpeed);\n    }\n\n    void ApplyWindSettings(float windSpeed)\n    {\n        // In a real implementation, this would affect cloth, vegetation, etc.\n        Physics.Wind = new Vector3(windSpeed, 0, 0);\n    }\n\n    /// <summary>\n    /// Cycle through environment presets\n    /// </summary>\n    public void CycleEnvironmentPreset()\n    {\n        if (environmentPresets.Length == 0) return;\n\n        currentPresetIndex = (currentPresetIndex + 1) % environmentPresets.Length;\n        ApplyEnvironmentPreset(environmentPresets[currentPresetIndex]);\n    }\n\n    /// <summary>\n    /// Start day-night cycle\n    /// </summary>\n    public void StartDayNightCycle()\n    {\n        isDayNightActive = true;\n    }\n\n    /// <summary>\n    /// Stop day-night cycle\n    /// </summary>\n    public void StopDayNightCycle()\n    {\n        isDayNightActive = false;\n    }\n\n    void Update()\n    {\n        if (isDayNightActive)\n        {\n            dayNightTimer += Time.deltaTime * 0.01f; // Slow progression\n\n            if (sunLight != null)\n            {\n                // Rotate sun based on time\n                float sunAngle = dayNightTimer * 360f;\n                sunLight.transform.rotation = Quaternion.Euler(sunAngle, 30, 0);\n\n                // Adjust intensity based on day/night curve\n                float intensityFactor = dayNightCycle.Evaluate((dayNightTimer % 1.0f));\n                sunLight.intensity = intensityFactor * 1.0f; // Base intensity\n\n                // Adjust ambient light\n                RenderSettings.ambientLight = Color.Lerp(Color.black, Color.white, intensityFactor * 0.5f);\n            }\n        }\n    }\n\n    /// <summary>\n    /// Get random spawn point for robot\n    /// </summary>\n    public Transform GetRandomSpawnPoint()\n    {\n        if (spawnPoints.Length == 0) return null;\n\n        int randomIndex = Random.Range(0, spawnPoints.Length);\n        return spawnPoints[randomIndex];\n    }\n\n    /// <summary>\n    /// Get specific spawn point by index\n    /// </summary>\n    public Transform GetSpawnPoint(int index)\n    {\n        if (index >= 0 && index < spawnPoints.Length)\n        {\n            return spawnPoints[index];\n        }\n        return null;\n    }\n\n    /// <summary>\n    /// Save current environment state\n    /// </summary>\n    public void SaveEnvironmentState()\n    {\n        // In a real implementation, this would save to a file or PlayerPrefs\n        Debug.Log("Environment state saved");\n    }\n\n    /// <summary>\n    /// Load environment state\n    /// </summary>\n    public void LoadEnvironmentState()\n    {\n        // In a real implementation, this would load from a file or PlayerPrefs\n        Debug.Log("Environment state loaded");\n    }\n}\n'})}),"\n",(0,o.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(e.p,{children:"Unity visualization provides powerful capabilities for creating immersive human-robot interaction experiences. Key considerations for effective implementation include:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Performance Optimization"}),": Balancing visual fidelity with real-time rendering requirements"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"ROS Integration"}),": Ensuring reliable communication between Unity and ROS 2 systems"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"User Experience"}),": Designing intuitive interfaces for robot control and monitoring"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Realism vs. Performance"}),": Finding the right balance for the intended application"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Modularity"}),": Creating reusable components that can adapt to different robot platforms"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(e.h3,{id:"conceptual",children:"Conceptual"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Explain the advantages and limitations of using Unity versus Gazebo for robotics visualization and human-robot interaction design."}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"logical",children:"Logical"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Analyze the trade-offs between visual realism and computational performance in Unity-based robot visualization. When would you prioritize one over the other in a robotics application?"}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"implementation-1",children:"Implementation"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsx)(e.li,{children:"Create a Unity visualization scene with a humanoid robot model that integrates with ROS 2, implements sensor data visualization, and provides a human-robot interaction interface for teleoperation and monitoring."}),"\n"]})]})}function d(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(u,{...n})}):u(n)}},8453(n,e,i){i.d(e,{R:()=>r,x:()=>s});var t=i(6540);const o={},a=t.createContext(o);function r(n){const e=t.useContext(a);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:r(n.components),t.createElement(a.Provider,{value:e},n.children)}}}]);